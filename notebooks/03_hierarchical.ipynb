{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hierarchical Models\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pymc-labs/ai_decision_workshop/blob/main/notebooks/03_hierarchical.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc as pm\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 75\n",
    "plt.rcParams['figure.figsize'] = (6.4, 3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prior(trace, **options):\n",
    "    return pm.plot_posterior(trace, group='prior', **options);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_posterior_predictive(trace, **options):\n",
    "    return pm.plot_posterior(trace, group='posterior_predictive', **options);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_samplers(model, *args, **options):\n",
    "    with model:\n",
    "        # Sample the prior predictive\n",
    "        prior_pred = pm.sample_prior_predictive()\n",
    "\n",
    "        # Sample from the posterior\n",
    "        trace = pm.sample(*args, **options)\n",
    "\n",
    "        # Sample from the posterior predictive\n",
    "        posterior_pred = pm.sample_posterior_predictive(trace)\n",
    "\n",
    "    trace.extend(prior_pred)\n",
    "    trace.extend(posterior_pred)\n",
    "    \n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "def run_campaign(d, n=100):\n",
    "    d['n'] += n\n",
    "    d['k'] += binom.rvs(n=n, p=d['p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandits Revisited\n",
    "\n",
    "Continuing the A/B testing example from the previous notebook, suppose we have an old email we have sent 200 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = dict(p=0.1, n=0, k=0)\n",
    "run_campaign(A, 200)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_proportion_A = A['k'] / A['n']\n",
    "obs_proportion_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a new version we have sent only 10 times, where the actual probability of conversion is 25%, close to the prior mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = dict(p=0.25, n=0, k=0)\n",
    "run_campaign(B, 10)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_proportion_B = B['k'] / B['n']\n",
    "obs_proportion_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the model that estimates conversion rates for A and B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_AB:\n",
    "    # Priors for conversion rates of A and B\n",
    "    conversion_rate_A = pm.Beta(\"conversion_rate_A\", alpha=2, beta=5)\n",
    "    conversion_rate_B = pm.Beta(\"conversion_rate_B\", alpha=2, beta=5)\n",
    "    \n",
    "    # Likelihoods for observed data\n",
    "    obs_A = pm.Binomial(\"obs_A\", p=conversion_rate_A, n=A['n'], observed=A['k'])\n",
    "    obs_B = pm.Binomial(\"obs_B\", p=conversion_rate_B, n=B['n'], observed=B['k'])\n",
    "    \n",
    "    trace = pm.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the posterior distributions, showing the observed proportions as reference values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_val = [obs_proportion_A, obs_proportion_B]\n",
    "pm.plot_posterior(trace, ref_val=ref_val);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, the conversion rates are independent -- the data from A doesn't affect the posterior distribution for B, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model_AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that means we are leaving information on the table: because A and B are similar, what we learn about A gives us information about the effectiveness of campaigns like this in general, which influences what we should believe about B.\n",
    "\n",
    "We can take advantage of this additional information by making the model hierarchical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this\n",
    "\n",
    "with pm.Model() as model_hierarchical:\n",
    "    # Priors for conversion rates of A and B\n",
    "    conversion_rate_A = pm.Beta(\"conversion_rate_A\", alpha=2, beta=5)\n",
    "    conversion_rate_B = pm.Beta(\"conversion_rate_B\", alpha=2, beta=5)\n",
    "    \n",
    "    # Likelihoods for observed data\n",
    "    obs_A = pm.Binomial(\"obs_A\", p=conversion_rate_A, n=A['n'], observed=A['k'])\n",
    "    obs_B = pm.Binomial(\"obs_B\", p=conversion_rate_B, n=B['n'], observed=B['k'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we sample, we simultaneously update beliefs about the conversion rates *and* the hyperpriors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model_hierarchical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace2 = run_samplers(model_hierarchical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the hyperpriors looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = ['alpha', 'beta']\n",
    "plot_prior(trace2, var_names=hyperparameters);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The means are close to 2 and 5, which were the fixed parameters we used in the previous version.\n",
    "And the priors for the conversion rates are similar to what we had before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['conversion_rate_A', 'conversion_rate_B']\n",
    "plot_prior(trace2, var_names=parameters);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the posteriors for the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace2, hyperparameters);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the conversion rates, showing the observed proportions as reference values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace2, parameters, ref_val=ref_val);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the effect of the hierarchical model is small -- with more classes, we would see more interaction.\n",
    "\n",
    "However, the hierarchical model has another useful feature: the posterior distributions of `alpha` and `beta` represent what we learned about campaigns in general, based on the results from A and B.\n",
    "Together they imply a posterior belief about the conversion rate of a new, untested version, C.\n",
    "\n",
    "First we extract the posterior distributions of the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = az.extract(trace2)\n",
    "alpha_samples = posterior_samples[\"alpha\"].values\n",
    "beta_samples = posterior_samples[\"beta\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use them to generate a sample of possible conversion rates for an email we have never sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "\n",
    "C_samples = beta(alpha_samples, beta_samples).rvs()\n",
    "pm.plot_posterior(C_samples);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the response rate of A is below the prior mean, the posterior mean is lower than the prior mean (0.29)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prediction\n",
    "\n",
    "Notice that `run_samplers` runs:\n",
    "\n",
    "* `pm.sample_prior_predictive`, which samples the prior and prior predictive distributions.\n",
    "\n",
    "* `pm.sample`, which samples the posterior distribution, and\n",
    "\n",
    "* `pm.sample_posterior_predictive`, which samples the posterior predictive distribution.\n",
    "\n",
    "We won't talk today about the prior predictive, but let's look at the posterior predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_posterior_predictive(trace2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These distributions predict the number of conversion we expect if we run the same campaign again -- with the same values of `n` -- given our posterior beliefs about the conversion rates.\n",
    "\n",
    "These distributions represent two sources of uncertainty:\n",
    "\n",
    "* We don't know exactly what the conversion rates are, and\n",
    "\n",
    "* Even if we did, we don't know how many conversions we would get.\n",
    "\n",
    "The first is *epistemic*, because it relates to what we know.\n",
    "The second is *aleatoric*, because it relates to randomness (literally \"dice\").\n",
    "\n",
    "As we learn more, the first source of uncertainty gets smaller; the second does not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
