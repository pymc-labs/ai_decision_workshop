{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hierarchical Models\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pymc-labs/ai_decision_workshop/blob/main/notebooks/03_hierarchical.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc as pm\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 75\n",
    "plt.rcParams['figure.figsize'] = (6.4, 3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prior(trace, **options):\n",
    "    return pm.plot_posterior(trace, group='prior', **options);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_posterior_predictive(trace, **options):\n",
    "    return pm.plot_posterior(trace, group='posterior_predictive', **options);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_samplers(model, *args, **options):\n",
    "    with model:\n",
    "        # Sample the prior predictive\n",
    "        prior_pred = pm.sample_prior_predictive()\n",
    "\n",
    "        # Sample from the posterior\n",
    "        trace = pm.sample(*args, **options)\n",
    "\n",
    "        # Sample from the posterior predictive\n",
    "        posterior_pred = pm.sample_posterior_predictive(trace)\n",
    "\n",
    "    trace.extend(prior_pred)\n",
    "    trace.extend(posterior_pred)\n",
    "    \n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "def run_campaign(d, n=100):\n",
    "    d['n'] += n\n",
    "    d['k'] += binom.rvs(n=n, p=d['p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandits Revisited\n",
    "\n",
    "Continuing the A/B testing example from the previous notebook, suppose we have an old email we have sent 200 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = dict(p=0.1, n=0, k=0)\n",
    "run_campaign(A, 200)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_proportion_A = A['k'] / A['n']\n",
    "obs_proportion_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a new version we have sent only 10 times, where the actual probability of conversion is 25%, close to the prior mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = dict(p=0.25, n=0, k=0)\n",
    "run_campaign(B, 10)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_proportion_B = B['k'] / B['n']\n",
    "obs_proportion_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the model that estimates conversion rates for A and B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_AB:\n",
    "    # Priors for conversion rates of A and B\n",
    "    conversion_rate_A = pm.Beta(\"conversion_rate_A\", alpha=2, beta=5)\n",
    "    conversion_rate_B = pm.Beta(\"conversion_rate_B\", alpha=2, beta=5)\n",
    "    \n",
    "    # Likelihoods for observed data\n",
    "    obs_A = pm.Binomial(\"obs_A\", p=conversion_rate_A, n=A['n'], observed=A['k'])\n",
    "    obs_B = pm.Binomial(\"obs_B\", p=conversion_rate_B, n=B['n'], observed=B['k'])\n",
    "    \n",
    "    trace = pm.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the posterior distributions, showing the observed proportions as reference values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_val = [obs_proportion_A, obs_proportion_B]\n",
    "pm.plot_posterior(trace, ref_val=ref_val);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, the conversion rates are independent -- the data from A doesn't affect the posterior distribution for B, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model_AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that means we are leaving information on the table: because A and B are similar, what we learn about A gives us information about the effectiveness of campaigns like this in general, which influences what we should believe about B.\n",
    "\n",
    "We can take advantage of this additional information by making the model hierarchical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this\n",
    "\n",
    "with pm.Model() as model_hierarchical:\n",
    "    # Priors for conversion rates of A and B\n",
    "    conversion_rate_A = pm.Beta(\"conversion_rate_A\", alpha=2, beta=5)\n",
    "    conversion_rate_B = pm.Beta(\"conversion_rate_B\", alpha=2, beta=5)\n",
    "    \n",
    "    # Likelihoods for observed data\n",
    "    obs_A = pm.Binomial(\"obs_A\", p=conversion_rate_A, n=A['n'], observed=A['k'])\n",
    "    obs_B = pm.Binomial(\"obs_B\", p=conversion_rate_B, n=B['n'], observed=B['k'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we sample, we simultaneously update beliefs about the conversion rates *and* the hyperpriors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model_hierarchical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace2 = run_samplers(model_hierarchical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the hyperpriors looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = ['alpha', 'beta']\n",
    "plot_prior(trace2, var_names=hyperparameters);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The means are close to 2 and 5, which were the fixed parameters we used in the previous version.\n",
    "And the priors for the conversion rates are similar to what we had before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['conversion_rate_A', 'conversion_rate_B']\n",
    "plot_prior(trace2, var_names=parameters);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the posteriors for the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace2, hyperparameters);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the conversion rates, showing the observed proportions as reference values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace2, parameters, ref_val=ref_val);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the effect of the hierarchical model is small -- with more classes, we would see more interaction.\n",
    "\n",
    "However, the hierarchical model has another useful feature: the posterior distributions of `alpha` and `beta` represent what we learned about campaigns in general, based on the results from A and B.\n",
    "Together they imply a posterior belief about the conversion rate of a new, untested version, C.\n",
    "\n",
    "First we extract the posterior distributions of the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = az.extract(trace2)\n",
    "alpha_samples = posterior_samples[\"alpha\"].values\n",
    "beta_samples = posterior_samples[\"beta\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use them to generate a sample of possible conversion rates for an email we have never sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "\n",
    "C_samples = beta(alpha_samples, beta_samples).rvs()\n",
    "pm.plot_posterior(C_samples);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the response rate of A is below the prior mean, the posterior mean is lower than the prior mean (0.29)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prediction\n",
    "\n",
    "Notice that `run_samplers` runs:\n",
    "\n",
    "* `pm.sample_prior_predictive`, which samples the prior and prior predictive distributions.\n",
    "\n",
    "* `pm.sample`, which samples the posterior distribution, and\n",
    "\n",
    "* `pm.sample_posterior_predictive`, which samples the posterior predictive distribution.\n",
    "\n",
    "We won't talk today about the prior predictive, but let's look at the posterior predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_posterior_predictive(trace2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These distributions predict the number of conversion we expect if we run the same campaign again -- with the same values of `n` -- given our posterior beliefs about the conversion rates.\n",
    "\n",
    "These distribution represent two sources of uncertainty:\n",
    "\n",
    "* We don't know exactly what the conversion rates are, and\n",
    "\n",
    "* Even if we did, we don't know how many conversions we would get.\n",
    "\n",
    "The first is *epistemic*, because it relates to what we know.\n",
    "The second is *aleatoric*, because it relates to randomness (literally \"dice\").\n",
    "\n",
    "As we learn more, the first source of uncertainty gets smaller; the second does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions of Probabilities\n",
    "\n",
    "Suppose we have two coins:\n",
    "\n",
    "* One is known to be fair, so the probability of heads is 50%.\n",
    "\n",
    "* The other is known to be biased, but it is equally likely that the probability of heads is 30% or 70%.\n",
    "\n",
    "If we flip each coin only once, the probability of heads is 50% for both coins.\n",
    "So it is tempting to think there is no difference: the outcome depends only on the mean probability.\n",
    "\n",
    "But that's not true in general. For example, suppose we toss each coin 10 times.\n",
    "For the fair coin, the distribution of outcomes is a simple binomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "binomial_dist = binom(n=n, p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can compute its PMF like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = np.arange(n+1)\n",
    "pmf_fair = binomial_dist.pmf(ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the biased coin, there are two possible distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomial_dist1 = binom(n=n, p=0.3)\n",
    "binomial_dist2 = binom(n=n, p=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can compute the overall PMF by averaging them (in this case because 30% and 70% are equally likely)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf1 = binomial_dist1.pmf(ks)\n",
    "pmf2 = binomial_dist2.pmf(ks)\n",
    "pmf_biased = (pmf1 + pmf2) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a mixture of two binomials.\n",
    "\n",
    "Here's what the two predictive distributions look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.45\n",
    "plt.bar(ks, pmf_fair, label='fair', align=\"edge\", width=-width)\n",
    "plt.bar(ks, pmf_biased, label='biased', align=\"edge\", width=width)\n",
    "plt.xlabel('Number of heads')\n",
    "plt.ylabel('PMF')\n",
    "plt.title('Predictive distributions')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are substantially different! In particular, the biased coin is more likely to produce extreme results.\n",
    "\n",
    "In general, if we have a distribution of probabilities, the predictive distribution is a mixture of binomials.\n",
    "\n",
    "In the philosophy of probability, so-called \"second order probabilities\" have sometimes been considered problematic.\n",
    "In the Bayesian interpretation of probability, they are unproblematically meaningful and practically useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Disaster\n",
    "\n",
    "Suppose you are designing a safety critical system, like a nuclear power plant, a medical device, or an autonomous vehicle.\n",
    "You have identified five components of the system that might fail, and estimated that there is a 5% chance that any one of them fails during a particular period of time.\n",
    "Fortunately, these components are redundant, so the system only fails if *all five of the components fail*.\n",
    "\n",
    "If the probability of failure is known to be precisely 5%, the probability of five simultaneous failures is 0.05 raised to the fifth power, which is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.05 ** 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let's see what happens if we add some uncertainty to that estimate.\n",
    "We'll use a beta distribution to represent uncertainty about the probability of failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta as beta_dist\n",
    "\n",
    "mean = 0.05\n",
    "std = 0.001\n",
    "\n",
    "alpha = mean * ((mean * (1 - mean)) / std**2 - 1)\n",
    "beta = (1 - mean) * ((mean * (1 - mean)) / std**2 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = beta_dist(alpha, beta)\n",
    "dist.mean(), dist.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what that distribution looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dist.rvs(1000)\n",
    "az.plot_kde(sample)\n",
    "plt.xlabel('Probability of component failure')\n",
    "plt.ylabel('Density');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the probability of **system failure**, we'll draw 1000 values from the beta distribution and compute the fifth power of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dist.rvs(1000)**5\n",
    "sample.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the distribution looks like for the probability of system failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_kde(sample)\n",
    "plt.xlabel('Probability of system failure')\n",
    "plt.ylabel('Density');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the uncertainty is small, the probability of system failure is still small.\n",
    "\n",
    "Exercise: Go back and increase `std`. The mean probability of component failure should stay the same, but see what happens to the mean probability of system failure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The way we are modeling this scenario, we assume that the probability of failure is the same for all five components. But the same effect happens if they are not identical, but correlated -- that is, if one of them turns out to be higher than expected, it's more likely that they others are, too. If they are uncorrelated, or only weakly correlated, we don't have the same problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
