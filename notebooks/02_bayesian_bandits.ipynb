{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian Bandits\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)]([![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pymc-labs/ai_decision_workshop/blob/main/notebooks/02_bayesian_bandits.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running in Google Colab, run this cell to install the `preliz` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import preliz\n",
    "except ImportError:\n",
    "    %pip install preliz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc as pm\n",
    "import preliz as pz\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 75\n",
    "plt.rcParams['figure.figsize'] = (6.4, 3.2)\n",
    "\n",
    "np.random.seed(RANDOM_SEED:=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prior(trace, **options):\n",
    "    return az.plot_posterior(trace, group='prior', **options);\n",
    "\n",
    "def plot_posterior_predictive(trace, **options):\n",
    "    return az.plot_posterior(trace, group='posterior_predictive', **options);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B Testing\n",
    "\n",
    "Let's get back to the first example from the previous notebook, estimating the conversion rate of an email campaign.\n",
    "\n",
    "For purposes of simulation, let's assume that the actual long run conversion rate for version A is 10%.\n",
    "We'll use a dictionary to keep track of this probability, `p`, the number of times we have tested this version, `n`, and the number of successful conversions, `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = dict(p=0.1, n=0, k=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run a campaign, we'll update this dictionary with the number of people we contact and the number of conversions, drawn from a binomial distribution with parameters `n` and `p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "def run_campaign(d, n=100):\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    d['n'] += n\n",
    "    d['k'] += binom.rvs(n=n, p=d['p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, suppose we send version A to 100 people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_campaign(A, 100)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the model from the previous notebook to estimate the conversion rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "\n",
    "    conversion_rate = pm.Beta(\"conversion_rate\", 2, 5)\n",
    "\n",
    "    pm.Binomial(\"n_signups\", p=conversion_rate, n=A['n'], observed=A['k'])\n",
    "\n",
    "model.to_graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    \n",
    "    trace = pm.sample(random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we introduce a new promotion that we think is more enticing, and for the sake of the example, we'll assume it is in fact more effective, so `p=0.15`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = dict(p=0.15, n=0, k=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we don't know yet that B is more effective, so we'll do an uneven A/B test where we send the new email to 20 people in the next batch of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_campaign(A, 80)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_campaign(B, 20)\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's update our beliefs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop Back to Here\n",
    "\n",
    "Here's the previous model extended to estimate conversion rates for A and B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_AB:\n",
    "    \n",
    "    # Priors for conversion rates of A and B\n",
    "    conversion_rate_A = pm.Beta(\"conversion_rate_A\", alpha=2, beta=5)\n",
    "    conversion_rate_B = pm.Beta(\"conversion_rate_B\", alpha=2, beta=5)\n",
    "    \n",
    "    # Likelihoods for observed data\n",
    "    obs_A = pm.Binomial(\"obs_A\", p=conversion_rate_A, n=A['n'], observed=A['k'])\n",
    "    obs_B = pm.Binomial(\"obs_B\", p=conversion_rate_B, n=B['n'], observed=B['k'])\n",
    "\n",
    "model_AB.to_graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_AB:\n",
    "    trace = pm.sample(random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the posterior distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can plot them on the same axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = az.extract(trace)\n",
    "samples_A = posterior[\"conversion_rate_A\"].values\n",
    "samples_B = posterior[\"conversion_rate_B\"].values\n",
    "\n",
    "az.plot_kde(samples_A, label=\"conversion_rate_A\")\n",
    "az.plot_kde(samples_B, label=\"conversion_rate_B\", plot_kwargs={\"color\": \"C1\"})\n",
    "\n",
    "plt.xlabel(\"Conversion Rate\")\n",
    "plt.title(\"Posterior Distributions\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, it looks like B is better, but the distributions overlap, so we might be tempted to run a hypothesis test.\n",
    "\n",
    "But rather than merely distinguishing between \"yes, there's a difference\" or \"no, there isn't\", it is more useful to compute the **distribution** of possible differences. We want to know **how different** the conversion rates are, not just whether they are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = samples_B - samples_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(diff, var_names=['x']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, we think B is better (positive difference), but it's still possible that A is better (negative difference).\n",
    "\n",
    "Here are the probabilities of superiority for A and B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_superior_A = (samples_A > samples_B).mean()\n",
    "p_superior_B = (samples_B > samples_A).mean()\n",
    "\n",
    "p_superior_A, p_superior_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At any point in time, these posterior distributions represent what we *believe* about A and B, but **how do we put those beliefs into action?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thompson Sampling\n",
    "\n",
    "One option is [Thompson sampling](https://en.wikipedia.org/wiki/Thompson_sampling), where we use A and B in proportion to their probability of superiority.\n",
    "As long as we are unsure, we use them both about equally.\n",
    "As we get confident that one is better, we use it more often.\n",
    "\n",
    "For the next 100 emails, we'll use the probability of superiority to choose the proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "n_A = (n * p_superior_A).round().astype(int)\n",
    "n_B = n - n_A\n",
    "\n",
    "n_A, n_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll simulate the campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_campaign(A, n_A)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_campaign(B, n_B)\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go back and run the model again.\n",
    "If you loop around a few times, you should see:\n",
    "\n",
    "* The estimated conversion rates for A and B converge to their true values.\n",
    "\n",
    "* The probability of superiority of B converges to 1.\n",
    "\n",
    "* We gradually use A less and B more.\n",
    "\n",
    "This strategy, also known as the [Bayesian bandit strategy](https://en.wikipedia.org/wiki/Multi-armed_bandit), is optimal in the sense that it maximizes expected utility given current beliefs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential updating\n",
    "\n",
    "One of the advertised advantages of Bayesian methods is that they allow us to incorporate prior information into our models. Often this prior information is obtained seqeuntially or incrementally.\n",
    "\n",
    "If we continue with our example, perhaps we have been given additional budget that allows us to collect additional data for the competing campaigns.\n",
    "\n",
    "It would make no sense to use a weakly informative prior for the new data. Instead, we should use a prior that is adaptively informed by the previous data. How can we do this?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior elicitation with PreliZ\n",
    "\n",
    "Our task is to extract information from the posterior distribution of the first experiment to inform the prior distribution for the second experiment.\n",
    "\n",
    "The key computational task is to determine the appropriate values of the Beta distribution that match our posterior information. We could manually use optimization methods for this, but we will take advantage of the `preliz` package to do this for us. `preliz` is a library aimed at helping practitioners choose prior distributions by implementing functions for facilitating prior elicitation.\n",
    "\n",
    "Specifically, the `maxent` function finds the **maximum entropy distribution** with mass in the interval defined by the lower and upper end-points.\n",
    "\n",
    "Let's start by extracting the posterior quantiles from the first experiment.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_A = np.percentile(samples_A, [5, 50, 95])\n",
    "quantiles_B = np.percentile(samples_B, [5, 50, 95])\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "az.plot_kde(samples_A, ax=axes[0])\n",
    "axes[0].axvline(quantiles_A[0], color='red', linestyle='--', alpha=0.7, label='5th percentile')\n",
    "axes[0].axvline(quantiles_A[1], color='red', linestyle='-', alpha=0.7, label='Median')\n",
    "axes[0].axvline(quantiles_A[2], color='red', linestyle='--', alpha=0.7, label='95th percentile')\n",
    "axes[0].set_title('A: Original Posterior')\n",
    "axes[0].legend()\n",
    "\n",
    "az.plot_kde(samples_B, ax=axes[1])\n",
    "axes[1].axvline(quantiles_B[0], color='red', linestyle='--', alpha=0.7, label='5th percentile')\n",
    "axes[1].axvline(quantiles_B[1], color='red', linestyle='-', alpha=0.7, label='Median')\n",
    "axes[1].axvline(quantiles_B[2], color='red', linestyle='--', alpha=0.7, label='95th percentile')\n",
    "axes[1].set_title('B: Original Posterior')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout();\n",
    "\n",
    "print(\"Posterior quantiles from first experiment:\")\n",
    "print(f\"A: 5% = {quantiles_A[0]:.3f}, 50% = {quantiles_A[1]:.3f}, 95% = {quantiles_A[2]:.3f}\")\n",
    "print(f\"B: 5% = {quantiles_B[0]:.3f}, 50% = {quantiles_B[1]:.3f}, 95% = {quantiles_B[2]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use `preliz.maxent()` to create Beta distributions that match our posterior information. We'll constrain 90% of the mass to fall between the 5th and 95th percentiles, and fix the median.\n",
    "\n",
    "Notice that  `preliz` has its own `Beta` class that we can use to parameterize Beta distributions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create informed priors using maxent\n",
    "prior_A_informed = pz.Beta()\n",
    "pz.maxent(\n",
    "    prior_A_informed, \n",
    "    lower=quantiles_A[0], \n",
    "    upper=quantiles_A[2], \n",
    "    mass=0.90,\n",
    "    fixed_stat=(\"median\", quantiles_A[1]),\n",
    "    plot=False\n",
    ")\n",
    "\n",
    "prior_B_informed = pz.Beta()\n",
    "pz.maxent(\n",
    "    prior_B_informed, \n",
    "    lower=quantiles_B[0], \n",
    "    upper=quantiles_B[2], \n",
    "    mass=0.90,\n",
    "    fixed_stat=(\"median\", quantiles_B[1]),\n",
    "    plot=False\n",
    ")\n",
    "\n",
    "print(\"Informed priors from maxent:\")\n",
    "print(f\"A: {prior_A_informed}\")\n",
    "print(f\"B: {prior_B_informed}\")\n",
    "\n",
    "# Compare with original weakly informative priors\n",
    "print(\"\\nOriginal weakly informative priors:\")\n",
    "print(\"A: Beta(2, 5)\")\n",
    "print(\"B: Beta(2, 5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how these parameterizations compare to the original weakly informative priors, and to the posterior samples from the first experiment.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "x = np.linspace(0, 0.4, 1000)\n",
    "axes[0].plot(x, prior_A_informed.pdf(x), label='Elicited Prior', color='blue', linewidth=2)\n",
    "axes[0].plot(x, pz.Beta(2, 5).pdf(x), label='Weakly Informative Prior', color='gray', linestyle='--')\n",
    "axes[0].legend()\n",
    "axes[0].set_xlabel('Conversion Rate (A)')\n",
    "\n",
    "axes[1].plot(x, prior_B_informed.pdf(x), label='Elicited Prior', color='orange', linewidth=2)\n",
    "axes[1].plot(x, pz.Beta(2, 5).pdf(x), label='Weakly Informative Prior', color='gray', linestyle='--')\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('Conversion Rate (B)')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(x, prior_A_informed.pdf(x), label='Elicited Prior', color='blue', linewidth=2)\n",
    "axes[0].hist(samples_A, bins=50, density=True, alpha=0.3, color='lightblue', label='Posterior Distribution')\n",
    "axes[0].legend()\n",
    "axes[0].set_xlabel('Conversion Rate (A)')\n",
    "\n",
    "axes[1].plot(x, prior_B_informed.pdf(x), label='Elicited Prior', color='orange', linewidth=2)\n",
    "axes[1].hist(samples_B, bins=50, density=True, alpha=0.3, color='lightsalmon', label='Posterior Distribution')\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('Conversion Rate (B)')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Experiment with New Data\n",
    "\n",
    "Now let's simulate a second experiment and fit two models: one with naive priors and one with informed priors from our previous experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_new = dict(p=0.1, n=0, k=0)\n",
    "B_new = dict(p=0.15, n=0, k=0)\n",
    "\n",
    "run_campaign(A_new, n=20)\n",
    "run_campaign(B_new, n=20)\n",
    "\n",
    "print(f\"New experiment results:\")\n",
    "print(f\"A: {A_new['k']}/{A_new['n']} = {A_new['k']/A_new['n']:.3f}\")\n",
    "print(f\"B: {B_new['k']}/{B_new['n']} = {B_new['k']/B_new['n']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with naive priors (same as original)\n",
    "with pm.Model() as model_naive:\n",
    "    conversion_rate_A_naive = pm.Beta(\"conversion_rate_A\", alpha=2, beta=5)\n",
    "    conversion_rate_B_naive = pm.Beta(\"conversion_rate_B\", alpha=2, beta=5)\n",
    "    \n",
    "    obs_A_naive = pm.Binomial(\"obs_A\", p=conversion_rate_A_naive, n=A_new['n'], observed=A_new['k'])\n",
    "    obs_B_naive = pm.Binomial(\"obs_B\", p=conversion_rate_B_naive, n=B_new['n'], observed=B_new['k'])\n",
    "\n",
    "# Model with informed priors\n",
    "with pm.Model() as model_informed:\n",
    "    conversion_rate_A_informed = pz.maxent(\n",
    "        pz.Beta(),\n",
    "        lower=quantiles_A[0], upper=quantiles_A[2],\n",
    "        mass=0.90,\n",
    "        fixed_stat=(\"median\", quantiles_A[1]),\n",
    "        plot=False\n",
    "    ).to_pymc(\"conversion_rate_A\")\n",
    "    conversion_rate_B_informed = pz.maxent(\n",
    "        pz.Beta(),\n",
    "        lower=quantiles_B[0], upper=quantiles_B[2],\n",
    "        mass=0.90,\n",
    "        fixed_stat=(\"median\", quantiles_B[1]),\n",
    "        plot=False\n",
    "    ).to_pymc(\"conversion_rate_B\")\n",
    "    \n",
    "    obs_A_informed = pm.Binomial(\"obs_A\", p=conversion_rate_A_informed, n=A_new['n'], observed=A_new['k'])\n",
    "    obs_B_informed = pm.Binomial(\"obs_B\", p=conversion_rate_B_informed, n=B_new['n'], observed=B_new['k'])\n",
    "\n",
    "print(\"Models created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from both models\n",
    "with model_naive:\n",
    "    trace_naive = pm.sample(random_seed=RANDOM_SEED)\n",
    "\n",
    "with model_informed:\n",
    "    trace_informed = pm.sample(random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Naive vs Informed Priors\n",
    "\n",
    "Let's compare how the different priors affect our posterior inference on the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract posterior samples\n",
    "posterior_naive = az.extract(trace_naive)\n",
    "posterior_informed = az.extract(trace_informed)\n",
    "\n",
    "samples_A_naive = posterior_naive[\"conversion_rate_A\"].values\n",
    "samples_B_naive = posterior_naive[\"conversion_rate_B\"].values\n",
    "samples_A_informed = posterior_informed[\"conversion_rate_A\"].values  \n",
    "samples_B_informed = posterior_informed[\"conversion_rate_B\"].values\n",
    "\n",
    "# Compare posterior summaries\n",
    "print(\"Posterior summaries for conversion rate A:\")\n",
    "print(f\"Naive prior:    mean = {samples_A_naive.mean():.3f}, std = {samples_A_naive.std():.3f}\")\n",
    "print(f\"Informed prior: mean = {samples_A_informed.mean():.3f}, std = {samples_A_informed.std():.3f}\")\n",
    "print(f\"True value: {A_new['p']}\")\n",
    "\n",
    "print(\"\\nPosterior summaries for conversion rate B:\")\n",
    "print(f\"Naive prior:    mean = {samples_B_naive.mean():.3f}, std = {samples_B_naive.std():.3f}\")\n",
    "print(f\"Informed prior: mean = {samples_B_informed.mean():.3f}, std = {samples_B_informed.std():.3f}\")\n",
    "print(f\"True value: {B_new['p']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "az.plot_kde(samples_A_naive, ax=axes[0], plot_kwargs={\"label\": \"Naive Prior\", \"color\": \"lightblue\"})\n",
    "az.plot_kde(samples_A_informed, ax=axes[0], plot_kwargs={\"label\": \"Informed Prior\", \"color\": \"blue\"})\n",
    "axes[0].axvline(A_new['p'], color='red', linestyle='--', label='True Value')\n",
    "axes[0].legend()\n",
    "axes[0].set_xlabel('Conversion Rate (A)')\n",
    "\n",
    "az.plot_kde(samples_B_naive, ax=axes[1], plot_kwargs={\"label\": \"Naive Prior\", \"color\": \"lightsalmon\"})\n",
    "az.plot_kde(samples_B_informed, ax=axes[1], plot_kwargs={\"label\": \"Informed Prior\", \"color\": \"orange\"})\n",
    "axes[1].axvline(B_new['p'], color='red', linestyle='--', label='True Value')\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('Conversion Rate (B)')\n",
    "\n",
    "diff_naive = samples_B_naive - samples_A_naive\n",
    "diff_informed = samples_B_informed - samples_A_informed\n",
    "\n",
    "az.plot_kde(diff_naive, ax=axes[2], plot_kwargs={\"label\": \"Naive Prior\", \"color\": \"gray\"})\n",
    "az.plot_kde(diff_informed, ax=axes[2], plot_kwargs={\"label\": \"Informed Prior\", \"color\": \"purple\"})\n",
    "axes[2].axvline(B_new['p'] - A_new['p'], color='red', linestyle='--', label='True Difference')\n",
    "axes[2].axvline(0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[2].legend()\n",
    "axes[2].set_xlabel('Conversion Rate Difference')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of decision-making, we benefit from a model that uses all of the available information. The posterior distributions are much more informative, mainly due to the large sample from conversion rate A in the first experiment. This is reflected in the narrowness of the posterior distributions.\n",
    "\n",
    "With such a small amount of data, we could easily have just run the second model using the weakly informative priors with all of the data. However in real-world applications, if the quantity of total data is large, it may be more efficient to update the prior incrementally with the new data as it becomes available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
